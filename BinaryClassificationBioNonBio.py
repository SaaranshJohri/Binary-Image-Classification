# -*- coding: utf-8 -*-
"""BiodegradableCheckMajorProject (2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UomG0Dhull1irnMXQ_3lqkzkhhwA6wrm
"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

!kaggle datasets download -d rayhanzamzamy/non-and-biodegradable-waste-dataset

import zipfile

zip_data = zipfile.ZipFile('/content/non-and-biodegradable-waste-dataset.zip')
zip_data.extractall('/content/')
zip_data.close()

import tensorflow as tf
from tensorflow import keras
from keras import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

import numpy as np
import matplotlib.pyplot as plt
import cv2

img = cv2.imread('/content/TEST/N/TEST_NBIODEG_ORI_1002.jpg')
img

plt.imshow(img)

img.shape

train_ds = tf.keras.utils.image_dataset_from_directory(

                  directory = '/content/TRAIN.1',
                  labels='inferred',
                  label_mode='int',
                  batch_size=32,
                  image_size=(256, 256),
              )

test_ds = tf.keras.utils.image_dataset_from_directory(

                  directory = '/content/TEST',
                  labels='inferred',
                  label_mode='int',
                  batch_size=32,
                  image_size=(256, 256),
              )

print (f'Number of Batches= {59922//32}')

def scale_down_px(image, label):

  image = tf.cast(image/255, tf.float32)

  return image, label

train_ds = train_ds.map(scale_down_px)
test_ds = test_ds.map(scale_down_px)

train_ds

test_ds

from keras.layers import BatchNormalization, Dropout

model = Sequential()

model.add(Conv2D(32, kernel_size=(3,3), padding='valid', activation='relu', input_shape=(256, 256, 3)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))

model.add(Conv2D(64, kernel_size=(3,3), padding='valid', activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))

model.add(Conv2D(128, kernel_size=(3,3), padding='valid', activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))

model.add(Flatten())

model.add(Dense(128, activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(1, activation='sigmoid'))

model.summary()

model.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')

history = model.fit(train_ds, validation_data = test_ds, epochs=10 )

plt.plot(history.history['accuracy'], color='r', label='Train_Accuracy')
plt.plot(history.history['val_accuracy'], color='b', label='Val_Accuracy')
plt.title('Measuring the Model Accuracy')
plt.xlabel('Number of Epochs')
plt.ylabel('Model Accuracy')
plt.legend()
plt.show()

plt.plot(history.history['loss'], color='r', label='Training_loss')
plt.plot(history.history['val_loss'], color='b', label='Val_loss')
plt.title('Measuring the Model Loss')
plt.xlabel('Number of Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

test_img = cv2.imread('/content/dog2.jpg')

plt.imshow(test_img)

test_img.shape

test_img = cv2.resize(test_img, (256, 256))

plt.imshow(test_img)

test_input = test_img.reshape(1, 256, 256, 3)

model.predict(test_input)[0][0]

output = model.predict(test_input)[0][0]
print(f'Output is: {output} \n')

if output < 0.5:
  print('This is a Non Biodegradable Thing.')
else:
  print('This is a Biodegradable Thing')























































